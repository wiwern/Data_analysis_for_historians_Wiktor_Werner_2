{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbb42f1-309d-4b0c-829d-68cba6d30a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e29864-256d-4232-863d-e6fe0bf9e7e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6a3f3ea-9be6-4fdf-a57d-3ac27ac38f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter dataset path (CSV/XLSX):  soldiers2023.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Column names & dtypes ===\n",
      "[0]                 time  dtype=object\n",
      "[1]              Wykleci  dtype=int64\n",
      "[2]                   AK  dtype=int64\n",
      "[3]                  NSZ  dtype=int64\n",
      "\n",
      "=== First rows ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>Wykleci</th>\n",
       "      <th>AK</th>\n",
       "      <th>NSZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004-01</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-02</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004-03</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004-04</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004-05</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      time  Wykleci  AK  NSZ\n",
       "0  2004-01        6   4    4\n",
       "1  2004-02       10   8    0\n",
       "2  2004-03        4  12    0\n",
       "3  2004-04        0  13    0\n",
       "4  2004-05        0   9    3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[hint] Best date-like column guess: 'time' (coverage ~100%)\n",
      "[hint] Numeric y candidates: ['Wykleci', 'AK', 'NSZ']\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter the DATE column name (as printed above), or leave blank for auto-detect / Year+Month:  time\n",
      "Enter the TARGET (y) column name (as printed above), or numeric index:  Wykleci\n",
      "Monthly aggregation ('mean' or 'sum') [default: mean]:  mean\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded & normalized → index=DatetimeIndex | rows=239 | columns=['Wykleci', 'AK', 'NSZ'] | y='Wykleci'\n",
      "Date range: 2004-01-01 → 2023-11-01 (monthly MS)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter intervention date (YYYY-MM or YYYY-MM-DD). Blank = auto-detect:  2011-03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRE : (Timestamp('2004-01-01 00:00:00'), Timestamp('2011-02-01 00:00:00'))\n",
      "POST: (Timestamp('2011-03-01 00:00:00'), Timestamp('2023-11-01 00:00:00'))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer supported. Convert to a numpy array before indexing instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 626>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo further fallbacks available.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 627\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    482\u001b[0m y_series \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39miloc[:,\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mindex, pd\u001b[38;5;241m.\u001b[39mDatetimeIndex):\n\u001b[0;32m--> 484\u001b[0m     \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_series\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    485\u001b[0m     vline_x \u001b[38;5;241m=\u001b[39m post[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/matplotlib/pyplot.py:2757\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2755\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[1;32m   2756\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\u001b[38;5;241m*\u001b[39margs, scalex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, scaley\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 2757\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2758\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscalex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaley\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaley\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2759\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/matplotlib/axes/_axes.py:1632\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1391\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1392\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1629\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1630\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1631\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[0;32m-> 1632\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[1;32m   1633\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[1;32m   1634\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/matplotlib/axes/_base.py:312\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    311\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 312\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/matplotlib/axes/_base.py:487\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[1;32m    484\u001b[0m         kw[prop_name] \u001b[38;5;241m=\u001b[39m val\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(xy) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m--> 487\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43m_check_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxy\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    488\u001b[0m     y \u001b[38;5;241m=\u001b[39m _check_1d(xy[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    489\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1327\u001b[0m, in \u001b[0;36m_check_1d\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1321\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings(record\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m w:\n\u001b[1;32m   1322\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\n\u001b[1;32m   1323\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malways\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1324\u001b[0m         category\u001b[38;5;241m=\u001b[39m\u001b[38;5;167;01mWarning\u001b[39;00m,\n\u001b[1;32m   1325\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSupport for multi-dimensional indexing\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1327\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mndim\n\u001b[1;32m   1328\u001b[0m     \u001b[38;5;66;03m# we have definitely hit a pandas index or series object\u001b[39;00m\n\u001b[1;32m   1329\u001b[0m     \u001b[38;5;66;03m# cast to a numpy array.\u001b[39;00m\n\u001b[1;32m   1330\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(w) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py:5199\u001b[0m, in \u001b[0;36mIndex.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   5197\u001b[0m \u001b[38;5;66;03m# Because we ruled out integer above, we always get an arraylike here\u001b[39;00m\n\u001b[1;32m   5198\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m-> 5199\u001b[0m     \u001b[43mdisallow_ndim_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5201\u001b[0m \u001b[38;5;66;03m# NB: Using _constructor._simple_new would break if MultiIndex\u001b[39;00m\n\u001b[1;32m   5202\u001b[0m \u001b[38;5;66;03m#  didn't override __getitem__\u001b[39;00m\n\u001b[1;32m   5203\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor\u001b[38;5;241m.\u001b[39m_simple_new(result, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexers/utils.py:343\u001b[0m, in \u001b[0;36mdisallow_ndim_indexing\u001b[0;34m(result)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03mHelper function to disallow multi-dimensional indexing on 1D Series/Index.\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;124;03min GH#30588.\u001b[39;00m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(result) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 343\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    344\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMulti-dimensional indexing (e.g. `obj[:, None]`) is no longer \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    345\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupported. Convert to a numpy array before indexing instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    346\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer supported. Convert to a numpy array before indexing instead."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Guided CausalImpact runner with robust patches + SARIMAX fallback.\n",
    "\n",
    "- Loads CSV/XLSX or DataFrame from path\n",
    "- Normalizes to monthly MS, cleans series\n",
    "- Tries python causalimpact with staged fixes & diagnostics (if installed)\n",
    "- If causalimpact returns inferences=None, falls back to SARIMAX deterministic counterfactual\n",
    "- Plots results and prints summaries\n",
    "\"\"\"\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "from typing import Optional, Tuple, Union, List, Dict, Any\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "os.environ.setdefault(\"NUMBA_DISABLE_JIT\", \"1\")\n",
    "\n",
    "# Optional CausalImpact\n",
    "_CI_OK = True\n",
    "try:\n",
    "    from causalimpact import CausalImpact\n",
    "except Exception as _ci_err:\n",
    "    _CI_OK = False\n",
    "    print(\"[info] CausalImpact unavailable:\", _ci_err)\n",
    "\n",
    "# ------------------ helpers: dates & loading ------------------\n",
    "def _coerce_monthlike_to_ts(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"Coerce YYYY-MM / YYYY/MM / YYYYMM / 200401 → Timestamp (month start).\"\"\"\n",
    "    if pd.api.types.is_numeric_dtype(s):\n",
    "        s = s.astype(\"Int64\").astype(str)\n",
    "    s = s.astype(str).str.strip()\n",
    "    s = s.str.replace(r\"[./]\", \"-\", regex=True)\n",
    "    s = s.str.replace(r\"^(\\d{4})(\\d{2})$\", r\"\\1-\\2\", regex=True)\n",
    "    return pd.to_datetime(s, format=\"%Y-%m\", errors=\"coerce\")\n",
    "\n",
    "def _guess_date_col(df: pd.DataFrame):\n",
    "    \"\"\"Pick a date-like column with best conversion coverage.\"\"\"\n",
    "    best, rate = None, 0.0\n",
    "    for c in df.columns:\n",
    "        try:\n",
    "            ts = pd.to_datetime(df[c], errors=\"coerce\")\n",
    "            r = ts.notna().mean()\n",
    "            if r > rate: best, rate = (c, ts), r\n",
    "        except Exception:\n",
    "            pass\n",
    "        try:\n",
    "            ts = _coerce_monthlike_to_ts(df[c])\n",
    "            r = ts.notna().mean()\n",
    "            if r > rate: best, rate = (c, ts), r\n",
    "        except Exception:\n",
    "            pass\n",
    "    return (best[0], rate) if best else (None, 0.0)\n",
    "\n",
    "def _maybe_from_year_month(df: pd.DataFrame):\n",
    "    \"\"\"Build dates from Year/Month columns (handles EN/PL variants).\"\"\"\n",
    "    yc = [c for c in df.columns if re.fullmatch(r\"(?i)year|rok|yyyy\", str(c))]\n",
    "    mc = [c for c in df.columns if re.fullmatch(r\"(?i)month|miesi[aą]c|mm\", str(c))]\n",
    "    if yc and mc:\n",
    "        y = pd.to_numeric(df[yc[0]], errors=\"coerce\").astype(\"Int64\")\n",
    "        m = pd.to_numeric(df[mc[0]], errors=\"coerce\").astype(\"Int64\")\n",
    "        return pd.to_datetime(y.astype(str) + \"-\" + m.astype(str), format=\"%Y-%m\", errors=\"coerce\")\n",
    "    return None\n",
    "\n",
    "def _force_monthly(df: pd.DataFrame, idx: Optional[Union[pd.Index, pd.Series]], agg=\"mean\") -> pd.DataFrame:\n",
    "    \"\"\"Normalize to monthly (MS). If no dates → numeric index.\"\"\"\n",
    "    out = df.copy()\n",
    "    if idx is None:\n",
    "        return out.reset_index(drop=True)\n",
    "    if isinstance(idx, pd.PeriodIndex):\n",
    "        idx = idx.to_timestamp(\"MS\")\n",
    "    idx = pd.to_datetime(idx, errors=\"coerce\")\n",
    "    out = out.loc[idx.notna()].copy()\n",
    "    out.index = idx[idx.notna()]\n",
    "    out = out.sort_index()\n",
    "    if isinstance(out.index, pd.DatetimeIndex):\n",
    "        if out.index.inferred_freq not in (\"MS\", \"M\"):\n",
    "            out = (out.resample(\"MS\").sum(min_count=1) if agg == \"sum\" else out.resample(\"MS\").mean())\n",
    "        else:\n",
    "            out = out.asfreq(\"MS\")\n",
    "    return out\n",
    "\n",
    "def load_any_series(path_or_df: Union[str, pd.DataFrame], y_col=None, date_col=None,\n",
    "                    monthly_agg=\"mean\", fill_y=True) -> Tuple[pd.DataFrame, str]:\n",
    "    \"\"\"Load CSV/XLSX/DataFrame → monthly DF (y first) cleaned & ready.\"\"\"\n",
    "    if isinstance(path_or_df, (str, bytes)):\n",
    "        p = str(path_or_df)\n",
    "        raw = pd.read_excel(p) if p.lower().endswith((\".xlsx\", \".xls\")) else pd.read_csv(p)\n",
    "    else:\n",
    "        raw = path_or_df.copy()\n",
    "\n",
    "    if isinstance(raw.index, pd.PeriodIndex):\n",
    "        raw.index = raw.index.to_timestamp(\"MS\")\n",
    "\n",
    "    # choose index\n",
    "    if date_col and date_col in raw.columns:\n",
    "        idx = pd.to_datetime(raw.pop(date_col), errors=\"coerce\")\n",
    "    else:\n",
    "        ts = _maybe_from_year_month(raw)\n",
    "        if ts is None:\n",
    "            guessed, _ = _guess_date_col(raw)\n",
    "            if guessed:\n",
    "                idx = pd.to_datetime(raw.pop(guessed), errors=\"coerce\")\n",
    "            else:\n",
    "                idx = None\n",
    "        else:\n",
    "            idx = ts\n",
    "\n",
    "    # numeric conversion\n",
    "    num = raw.copy()\n",
    "    for c in num.columns:\n",
    "        num[c] = pd.to_numeric(num[c], errors=\"coerce\")\n",
    "\n",
    "    # pick y\n",
    "    if y_col is None:\n",
    "        num_cols = [c for c in num.columns if pd.api.types.is_numeric_dtype(num[c])]\n",
    "        if not num_cols:\n",
    "            raise ValueError(\"No numeric columns found for y.\")\n",
    "        y_col = num_cols[0]\n",
    "    yname = num.columns[y_col] if isinstance(y_col, int) else y_col\n",
    "    cols = [yname] + [c for c in num.columns if c != yname]\n",
    "    num = num[cols].copy()\n",
    "\n",
    "    # monthly + cleaning\n",
    "    data = _force_monthly(num, idx, agg=monthly_agg)\n",
    "\n",
    "    # Interpolate/Fill: stronger fill strategy to avoid NAs inside pre/post\n",
    "    if fill_y:\n",
    "        data.iloc[:, 0] = data.iloc[:, 0].interpolate(limit_direction=\"both\").ffill().bfill()\n",
    "    data = data.dropna(subset=[data.columns[0]])\n",
    "    for c in data.columns[1:]:\n",
    "        if data[c].isna().any():\n",
    "            data[c] = data[c].interpolate(limit_direction=\"both\").ffill().bfill()\n",
    "\n",
    "    # drop near-constant covariates\n",
    "    drop_const = [c for c in data.columns[1:] if data[c].std(skipna=True) < 1e-12 or data[c].nunique(dropna=True) < 2]\n",
    "    if drop_const:\n",
    "        print(f\"[info] Dropping near-constant covariates: {drop_const}\")\n",
    "        data = data.drop(columns=drop_const)\n",
    "\n",
    "    # ensure numeric dtype\n",
    "    for c in data.columns:\n",
    "        data[c] = pd.to_numeric(data[c], errors=\"coerce\").astype(float)\n",
    "\n",
    "    return data, yname\n",
    "\n",
    "def preview_file(path: str, n=5):\n",
    "    \"\"\"Print columns, dtypes, head; give hints for date/y selection.\"\"\"\n",
    "    raw = pd.read_excel(path) if path.lower().endswith((\".xlsx\", \".xls\")) else pd.read_csv(path)\n",
    "    print(\"\\n=== Column names & dtypes ===\")\n",
    "    d = raw.dtypes.astype(str)\n",
    "    for i, c in enumerate(raw.columns):\n",
    "        print(f\"[{i}] {c:>20s}  dtype={d[c]}\")\n",
    "    print(\"\\n=== First rows ===\")\n",
    "    try:\n",
    "        display(raw.head(n))\n",
    "    except Exception:\n",
    "        print(raw.head(n))\n",
    "    # hints\n",
    "    guess, rate = _guess_date_col(raw)\n",
    "    ym = _maybe_from_year_month(raw)\n",
    "    if guess:\n",
    "        print(f\"\\n[hint] Best date-like column guess: '{guess}' (coverage ~{rate:.0%})\")\n",
    "    if ym is not None:\n",
    "        print(\"[hint] Detected Year/Month columns that can build dates.\")\n",
    "    nums = [c for c in raw.columns if pd.api.types.is_numeric_dtype(raw[c])]\n",
    "    if nums:\n",
    "        print(\"[hint] Numeric y candidates:\", nums)\n",
    "\n",
    "# ------------------ CI patches: staged fixes ------------------\n",
    "def _ci_try(df: pd.DataFrame, pre: tuple, post: tuple, label: str, extra_model_args: dict = None):\n",
    "    \"\"\"Try CausalImpact and return (ok, impact or None, message).\"\"\"\n",
    "    # convert to list form that CausalImpact expects\n",
    "    pre_list = [pre[0], pre[1]]\n",
    "    post_list = [post[0], post[1]]\n",
    "    # diagnostics\n",
    "    print(f\"[ci_try] Attempt '{label}': data shape={df.shape}\")\n",
    "    print(f\"[ci_try] dtypes:\\n{df.dtypes}\")\n",
    "    if isinstance(df.index, pd.DatetimeIndex):\n",
    "        print(f\"[ci_try] index freq inferred: {df.index.inferred_freq}  first/last: {df.index.min()} / {df.index.max()}\")\n",
    "    # ensure no NA\n",
    "    if df.isna().any().any():\n",
    "        print(\"[ci_try] Warning: input contains NAs; filling with linear interp + bfill/ffill.\")\n",
    "        df = df.interpolate(limit_direction=\"both\").ffill().bfill()\n",
    "    # require float dtype\n",
    "    for c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\").astype(float)\n",
    "    # ensure pre/post endpoints exist in index for datetime\n",
    "    if isinstance(df.index, pd.DatetimeIndex):\n",
    "        if pre_list[0] not in df.index or pre_list[1] not in df.index or post_list[0] not in df.index or post_list[1] not in df.index:\n",
    "            print(\"[ci_try] Nudging pre/post to closest available index values.\")\n",
    "            def _closest(ts):\n",
    "                if ts in df.index: return ts\n",
    "                # choose nearest by position\n",
    "                pos = np.searchsorted(df.index, ts)\n",
    "                pos = min(max(pos, 0), len(df.index)-1)\n",
    "                return df.index[pos]\n",
    "            pre_list = [_closest(pre_list[0]), _closest(pre_list[1])]\n",
    "            post_list = [_closest(post_list[0]), _closest(post_list[1])]\n",
    "            print(f\"[ci_try] Using pre={pre_list}, post={post_list}\")\n",
    "    # default model args\n",
    "    model_args = {\"niter\": 2000, \"standardize\": True}\n",
    "    if extra_model_args:\n",
    "        model_args.update(extra_model_args)\n",
    "    try:\n",
    "        impact = CausalImpact(df, pre_list, post_list, model_args=model_args)\n",
    "        if getattr(impact, \"inferences\", None) is not None:\n",
    "            print(f\"[OK] CausalImpact succeeded: {label}\")\n",
    "            return True, impact, \"\"\n",
    "        # Some CausalImpact runs construct object but inferences missing -> diagnostic\n",
    "        info = f\"[warn] CausalImpact returned inferences=None ({label}). Try: check pre/post lengths, model_args, or underlying sampler.\"\n",
    "        return False, None, info\n",
    "    except Exception as e:\n",
    "        return False, None, f\"[warn] CausalImpact failed ({label}): {e}\"\n",
    "\n",
    "def _filter_by_corr_pre(df: pd.DataFrame, pre: tuple, thr=0.2) -> pd.DataFrame:\n",
    "    \"\"\"Keep covariates correlated with y (|r|>=thr) in pre-period.\"\"\"\n",
    "    ycol = df.columns[0]\n",
    "    if isinstance(df.index, pd.DatetimeIndex):\n",
    "        pre_df = df.loc[pre[0]:pre[1]]\n",
    "    else:\n",
    "        pre_df = df.iloc[pre[0]:pre[1]+1]\n",
    "    cors = pre_df.corr(numeric_only=True)[ycol].drop(index=ycol).sort_values(ascending=False)\n",
    "    keep = cors[cors.abs() >= thr].index.tolist()\n",
    "    print(f\"[patch] Keeping covariates by pre-corr (|r|≥{thr}):\", keep)\n",
    "    return df[[ycol] + keep].copy()\n",
    "\n",
    "def _drop_collinear_pre(df: pd.DataFrame, pre: tuple, cutoff=0.98) -> pd.DataFrame:\n",
    "    \"\"\"Drop covariates with pairwise |r|>cutoff in pre-period.\"\"\"\n",
    "    if df.shape[1] <= 2:\n",
    "        return df\n",
    "    X = df.iloc[:, 1:].copy()\n",
    "    if isinstance(df.index, pd.DatetimeIndex):\n",
    "        preX = X.loc[pre[0]:pre[1]]\n",
    "    else:\n",
    "        preX = X.iloc[pre[0]:pre[1]+1]\n",
    "    C = preX.corr().abs()\n",
    "    upper = C.where(np.triu(np.ones(C.shape), k=1).astype(bool))\n",
    "    to_drop = [col for col in upper.columns if any(upper[col] > cutoff)]\n",
    "    if to_drop:\n",
    "        print(f\"[patch] Dropping collinear covariates (|r|>{cutoff}):\", to_drop)\n",
    "        X = X.drop(columns=to_drop, errors=\"ignore\")\n",
    "    return pd.concat([df.iloc[:, [0]], X], axis=1)\n",
    "\n",
    "def _enforce_consecutive_months(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Ensure monthly MS frequency; interpolate covariates if needed.\"\"\"\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        return df\n",
    "    out = df.asfreq(\"MS\")\n",
    "    for c in out.columns[1:]:\n",
    "        if out[c].isna().any():\n",
    "            out[c] = out[c].interpolate(limit_direction=\"both\").ffill().bfill()\n",
    "    # also ensure target filled\n",
    "    if out.iloc[:,0].isna().any():\n",
    "        out.iloc[:,0] = out.iloc[:,0].interpolate(limit_direction=\"both\").ffill().bfill()\n",
    "    return out\n",
    "\n",
    "def _nudge_split_if_needed(df: pd.DataFrame, pre: tuple, post: tuple) -> Tuple[tuple, tuple]:\n",
    "    \"\"\"If split lands on a gap, nudge post start to nearest available and adjust pre end.\"\"\"\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        return pre, post\n",
    "    # find actual nearest available for post[0]\n",
    "    if post[0] not in df.index:\n",
    "        # nearest index >= original\n",
    "        idx = df.index[df.index >= post[0]]\n",
    "        if len(idx) == 0:\n",
    "            idx = df.index  # fallback to last\n",
    "        new_post_start = idx[0]\n",
    "        new_pre_end = df.index[df.index.get_loc(new_post_start) - 1] if new_post_start != df.index[0] else new_post_start\n",
    "        pre = (pre[0], new_pre_end)\n",
    "        post = (new_post_start, post[1])\n",
    "        print(f\"[patch] Nudged split → POST starts at {new_post_start.date()}, PRE ends at {new_pre_end.date()}\")\n",
    "    return pre, post\n",
    "\n",
    "# ------------------ periods & fallback DID/OLS / SARIMAX ------------------\n",
    "def detect_intervention(df: pd.DataFrame, method=\"cusum\", min_pre=30, min_post=10):\n",
    "    y = df.iloc[:,0].astype(float).values\n",
    "    n = len(df)\n",
    "    if n < (min_pre+min_post+1):\n",
    "        cut = max(min_pre, int(round(0.7*n))); cut = min(cut, n-min_post)\n",
    "        return df.index[cut] if isinstance(df.index, pd.DatetimeIndex) else cut\n",
    "    if method == \"maxdiff\":\n",
    "        diffs = np.abs(np.diff(y))\n",
    "        k = int(np.nanargmax(diffs)) + 1 if np.isfinite(diffs).any() else int(round(0.7*n))\n",
    "        cut = k\n",
    "    else:\n",
    "        yy = (y - np.nanmean(y)) / (np.nanstd(y) + 1e-12)\n",
    "        cs = np.nancumsum(yy)\n",
    "        t = np.arange(1, n+1)\n",
    "        m, b = np.linalg.lstsq(np.vstack([t, np.ones(n)]).T, cs, rcond=None)[0]\n",
    "        csd = cs - (m*t + b)\n",
    "        k = int(np.nanargmax(np.abs(csd)))\n",
    "        cut = max(1, min(n-1, k+1))\n",
    "    cut = max(min_pre, min(n-min_post, cut))\n",
    "    return df.index[cut] if isinstance(df.index, pd.DatetimeIndex) else cut\n",
    "\n",
    "def make_periods_safe(df: pd.DataFrame, intervention=None, mode=\"date\", ratio=0.7):\n",
    "    if isinstance(df.index, pd.DatetimeIndex):\n",
    "        if mode == \"date\" and intervention is not None:\n",
    "            t0 = pd.to_datetime(intervention)\n",
    "            pre_idx  = df.index[df.index < t0]\n",
    "            post_idx = df.index[df.index >= t0]\n",
    "            if len(pre_idx)>0 and len(post_idx)>0:\n",
    "                pre  = (df.index.min(), pre_idx.max())\n",
    "                post = (post_idx.min(), df.index.max())\n",
    "                return pre, post\n",
    "        k = max(30, int(round(len(df)*ratio))); k = min(k, len(df)-10)\n",
    "        return (df.index[0], df.index[k-1]), (df.index[k], df.index[-1])\n",
    "    else:\n",
    "        n = len(df)\n",
    "        if isinstance(intervention, int):\n",
    "            k = min(max(30, intervention), n-10)\n",
    "        else:\n",
    "            k = max(30, int(round(n*ratio))); k = min(k, n-10)\n",
    "        return (0, k-1), (k, n-1)\n",
    "\n",
    "def run_did_ols(df: pd.DataFrame, pre: tuple, post: tuple):\n",
    "    import statsmodels.api as sm\n",
    "    if isinstance(pre[0], pd.Timestamp):\n",
    "        is_post = (df.index >= post[0]).astype(int)\n",
    "    else:\n",
    "        is_post = (np.arange(len(df)) >= post[0]).astype(int)\n",
    "    y = df.iloc[:,0]\n",
    "    X = pd.concat([pd.Series(is_post, index=df.index, name=\"post\"), df.iloc[:,1:]], axis=1)\n",
    "    X = sm.add_constant(X, has_constant=\"add\")\n",
    "    res = sm.OLS(y, X).fit(cov_type=\"HAC\", cov_kwds={\"maxlags\":3})\n",
    "    print(res.summary().tables[1])\n",
    "    return res\n",
    "\n",
    "def run_sarimax_counterfactual(df: pd.DataFrame, pre: tuple, post: tuple,\n",
    "                               order=(1,0,1), seasonal_order=(0,0,0,0), alpha=0.05):\n",
    "    \"\"\"\n",
    "    Fit SARIMAX on pre-period (with exog covariates if available), forecast post, and compute effects.\n",
    "    Returns dict with forecast_mean, forecast_ci, effect, cumulative effect, and model result.\n",
    "    \"\"\"\n",
    "    import statsmodels.api as sm\n",
    "\n",
    "    y = df.iloc[:, 0]\n",
    "    exog = df.iloc[:, 1:] if df.shape[1] > 1 else None\n",
    "\n",
    "    # Select slices (handles datetime and integer indices)\n",
    "    if isinstance(df.index, pd.DatetimeIndex):\n",
    "        y_pre = y.loc[pre[0]:pre[1]]\n",
    "        y_post = y.loc[post[0]:post[1]]\n",
    "        exog_pre = exog.loc[pre[0]:pre[1]] if exog is not None else None\n",
    "        exog_post = exog.loc[post[0]:post[1]] if exog is not None else None\n",
    "    else:\n",
    "        y_pre = y.iloc[pre[0]:pre[1]+1]\n",
    "        y_post = y.iloc[post[0]:post[1]+1]\n",
    "        exog_pre = exog.iloc[pre[0]:pre[1]+1] if exog is not None else None\n",
    "        exog_post = exog.iloc[post[0]:post[1]+1] if exog is not None else None\n",
    "\n",
    "    if len(y_pre) < 10:\n",
    "        print(\"[sarimax] Warning: very short pre-period; results may be unstable.\")\n",
    "\n",
    "    model = sm.tsa.SARIMAX(endog=y_pre, exog=exog_pre, order=order, seasonal_order=seasonal_order,\n",
    "                           enforce_stationarity=False, enforce_invertibility=False)\n",
    "    res = model.fit(disp=False)\n",
    "    steps = len(y_post)\n",
    "    if steps <= 0:\n",
    "        raise ValueError(\"Post period has zero length for forecasting.\")\n",
    "\n",
    "    if exog_post is not None and len(exog_post) == steps:\n",
    "        pred = res.get_forecast(steps=steps, exog=exog_post)\n",
    "    else:\n",
    "        pred = res.get_forecast(steps=steps)\n",
    "\n",
    "    mean_forecast = pred.predicted_mean\n",
    "    try:\n",
    "        ci = pred.conf_int(alpha=alpha)\n",
    "    except Exception:\n",
    "        # fallback: build CI from mean +/- 1.96 * sqrt(var_pred_mean)\n",
    "        var = pred.var_pred_mean if hasattr(pred, \"var_pred_mean\") else None\n",
    "        if var is not None:\n",
    "            se = np.sqrt(var)\n",
    "            lower = mean_forecast - 1.96*se\n",
    "            upper = mean_forecast + 1.96*se\n",
    "            ci = pd.DataFrame({0: lower, 1: upper}, index=mean_forecast.index)\n",
    "            # name columns to be consistent\n",
    "            ci.columns = [\"lower\", \"upper\"]\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "    # Align indices with observed post\n",
    "    mean_forecast.index = y_post.index\n",
    "    ci.index = y_post.index\n",
    "\n",
    "    # Extract CI column names robustly\n",
    "    if ci.shape[1] >= 2:\n",
    "        # try common names\n",
    "        if \"lower y\" in ci.columns and \"upper y\" in ci.columns:\n",
    "            lower_ci = ci[\"lower y\"]\n",
    "            upper_ci = ci[\"upper y\"]\n",
    "        elif \"lower\" in ci.columns and \"upper\" in ci.columns:\n",
    "            lower_ci = ci[\"lower\"]\n",
    "            upper_ci = ci[\"upper\"]\n",
    "        else:\n",
    "            # fallback: first = lower, second = upper\n",
    "            lower_ci = ci.iloc[:,0]\n",
    "            upper_ci = ci.iloc[:,1]\n",
    "    else:\n",
    "        raise RuntimeError(\"Could not parse forecast CI columns.\")\n",
    "\n",
    "    # Pointwise effects\n",
    "    effect = y_post - mean_forecast\n",
    "    effect_lower = y_post - upper_ci\n",
    "    effect_upper = y_post - lower_ci\n",
    "\n",
    "    # Cumulative effect and approximate CI (sum variances if var_pred_mean available)\n",
    "    cum_effect = effect.sum()\n",
    "    try:\n",
    "        if hasattr(pred, \"var_pred_mean\"):\n",
    "            var_forecast = pred.var_pred_mean\n",
    "            cum_var = np.nansum(var_forecast)\n",
    "            cum_se = np.sqrt(cum_var)\n",
    "            cum_ci_lower = cum_effect - 1.96 * cum_se\n",
    "            cum_ci_upper = cum_effect + 1.96 * cum_se\n",
    "        else:\n",
    "            cum_ci_lower, cum_ci_upper = np.nan, np.nan\n",
    "    except Exception:\n",
    "        cum_ci_lower, cum_ci_upper = np.nan, np.nan\n",
    "\n",
    "    print(\"[sarimax] SARIMAX fit finished. Params:\")\n",
    "    print(res.params)\n",
    "    print(f\"[sarimax] Post length: {steps}; cumulative effect={cum_effect:.3f}  95%CI=({cum_ci_lower:.3f}, {cum_ci_upper:.3f})\")\n",
    "\n",
    "    return {\n",
    "        \"model_result\": res,\n",
    "        \"forecast_mean\": mean_forecast,\n",
    "        \"forecast_ci_lower\": lower_ci,\n",
    "        \"forecast_ci_upper\": upper_ci,\n",
    "        \"effect\": effect,\n",
    "        \"effect_lower\": effect_lower,\n",
    "        \"effect_upper\": effect_upper,\n",
    "        \"cum_effect\": cum_effect,\n",
    "        \"cum_ci\": (cum_ci_lower, cum_ci_upper),\n",
    "        \"y_post\": y_post\n",
    "    }\n",
    "\n",
    "# ------------------ interactive flow ------------------\n",
    "def main():\n",
    "    path = input(\"Enter dataset path (CSV/XLSX): \").strip()\n",
    "    preview_file(path)  # help the user pick columns\n",
    "\n",
    "    date_in = input(\"\\nEnter the DATE column name (as printed above), or leave blank for auto-detect / Year+Month: \").strip()\n",
    "    date_arg = None if date_in == \"\" else date_in\n",
    "    y_in = input(\"Enter the TARGET (y) column name (as printed above), or numeric index: \").strip()\n",
    "    y_arg = int(y_in) if (y_in.isdigit()) else y_in\n",
    "    agg = (input(\"Monthly aggregation ('mean' or 'sum') [default: mean]: \").strip() or \"mean\").lower()\n",
    "\n",
    "    data, yname = load_any_series(path, y_col=y_arg, date_col=date_arg, monthly_agg=agg, fill_y=True)\n",
    "    print(f\"\\nLoaded & normalized → index={type(data.index).__name__} | rows={len(data)} | columns={list(data.columns)} | y='{yname}'\")\n",
    "\n",
    "    # pick/ask intervention\n",
    "    if isinstance(data.index, pd.DatetimeIndex):\n",
    "        print(f\"Date range: {data.index.min().date()} → {data.index.max().date()} (monthly MS)\")\n",
    "        t0_in = input(\"Enter intervention date (YYYY-MM or YYYY-MM-DD). Blank = auto-detect: \").strip()\n",
    "        if t0_in == \"\":\n",
    "            t0 = detect_intervention(data, method=\"cusum\", min_pre=30, min_post=10); mode = \"date\"\n",
    "            print(f\"[auto] Intervention picked: {t0}\")\n",
    "        else:\n",
    "            t0 = t0_in; mode = \"date\"\n",
    "    else:\n",
    "        print(f\"Row index range: 0..{len(data)-1}\")\n",
    "        t0_in = input(\"Enter intervention row index (integer). Blank = auto-detect: \").strip()\n",
    "        if t0_in == \"\":\n",
    "            t0 = detect_intervention(data, method=\"cusum\", min_pre=30, min_post=10); mode = \"index\"\n",
    "            print(f\"[auto] Intervention picked (row): {t0}\")\n",
    "        else:\n",
    "            t0 = int(t0_in); mode = \"index\"\n",
    "\n",
    "    pre, post = make_periods_safe(data, intervention=t0, mode=mode)\n",
    "    pre, post = _nudge_split_if_needed(data, pre, post)\n",
    "    print(\"PRE :\", pre)\n",
    "    print(\"POST:\", post)\n",
    "\n",
    "    # quick visualization of y with intervention\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    y_series = data.iloc[:,0]\n",
    "    if isinstance(data.index, pd.DatetimeIndex):\n",
    "        plt.plot(data.index, y_series, lw=1.2)\n",
    "        vline_x = post[0]\n",
    "    else:\n",
    "        plt.plot(range(len(y_series)), y_series.values, lw=1.2)\n",
    "        vline_x = post[0]\n",
    "    plt.axvline(vline_x, ls=\"--\")\n",
    "    plt.title(f\"Target series '{yname}' with intervention marker\")\n",
    "    plt.xlabel(\"Time\" if isinstance(data.index, pd.DatetimeIndex) else \"Row\")\n",
    "    plt.ylabel(yname)\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "    # ===================== CausalImpact with staged fixes =====================\n",
    "    ci_success, impact = False, None\n",
    "    if _CI_OK:\n",
    "        # Try 0: original\n",
    "        ok, imp, msg = _ci_try(data, pre, post, \"original\")\n",
    "        if not ok and msg: print(msg)\n",
    "        ci_success, impact = ok, imp\n",
    "\n",
    "        # Try 0b: original with larger niter\n",
    "        if not ci_success:\n",
    "            ok, imp, msg = _ci_try(data, pre, post, \"original (niter=4000)\", extra_model_args={\"niter\":4000})\n",
    "            if not ok and msg: print(msg)\n",
    "            ci_success, impact = ok, imp\n",
    "\n",
    "        # Try 0c: original with larger niter & no standardization\n",
    "        if not ci_success:\n",
    "            ok, imp, msg = _ci_try(data, pre, post, \"original (niter=8000, std=False)\",\n",
    "                                  extra_model_args={\"niter\":8000, \"standardize\":False})\n",
    "            if not ok and msg: print(msg)\n",
    "            ci_success, impact = ok, imp\n",
    "\n",
    "        # Try 1: univariate only\n",
    "        if not ci_success:\n",
    "            df_uni = data[[data.columns[0]]].copy()\n",
    "            ok, imp, msg = _ci_try(df_uni, pre, post, \"univariate y\")\n",
    "            if not ok and msg: print(msg)\n",
    "            else: data = df_uni\n",
    "            ci_success, impact = ok, imp\n",
    "\n",
    "        # Try 2: keep covariates with |r| >= 0.2 in pre-period\n",
    "        if not ci_success and data.shape[1] > 1:\n",
    "            df_corr = _filter_by_corr_pre(data, pre, thr=0.2)\n",
    "            ok, imp, msg = _ci_try(df_corr, pre, post, \"filtered by pre-corr\")\n",
    "            if not ok and msg: print(msg)\n",
    "            else: data = df_corr\n",
    "            ci_success, impact = ok, imp\n",
    "\n",
    "        # Try 3: drop collinear covariates (|r|>0.98 in pre)\n",
    "        if not ci_success and data.shape[1] > 2:\n",
    "            df_dec = _drop_collinear_pre(data, pre, cutoff=0.98)\n",
    "            ok, imp, msg = _ci_try(df_dec, pre, post, \"dropped collinear\")\n",
    "            if not ok and msg: print(msg)\n",
    "            else: data = df_dec\n",
    "            ci_success, impact = ok, imp\n",
    "\n",
    "        # Try 4: enforce consecutive months and try again\n",
    "        if not ci_success and isinstance(data.index, pd.DatetimeIndex):\n",
    "            df_cons = _enforce_consecutive_months(data)\n",
    "            pre2, post2 = _nudge_split_if_needed(df_cons, pre, post)\n",
    "            ok, imp, msg = _ci_try(df_cons, pre2, post2, \"consecutive months + nudged split\")\n",
    "            if not ok and msg: print(msg)\n",
    "            else:\n",
    "                data, pre, post = df_cons, pre2, post2\n",
    "            ci_success, impact = ok, imp\n",
    "\n",
    "    # Final report\n",
    "    if ci_success:\n",
    "        print(\"\\n===== CausalImpact SUMMARY =====\")\n",
    "        try:\n",
    "            print(impact.summary())\n",
    "        except Exception:\n",
    "            try:\n",
    "                print(str(impact))\n",
    "            except Exception:\n",
    "                print(\"[info] Could not print Impact.summary()\")\n",
    "        try:\n",
    "            display(impact.plot())\n",
    "        except Exception:\n",
    "            try:\n",
    "                impact.plot()\n",
    "                plt.show()\n",
    "            except Exception:\n",
    "                pass\n",
    "        print(\"Method used: CausalImpact\")\n",
    "    else:\n",
    "        print(\"\\n[info] CausalImpact unavailable or returned no inferences in all attempts.\")\n",
    "        print(\"[info] Falling back to SARIMAX counterfactual (deterministic).\")\n",
    "        try:\n",
    "            sar = run_sarimax_counterfactual(data, pre, post, order=(1,0,1))\n",
    "            # print and plot results\n",
    "            fm = sar[\"forecast_mean\"]\n",
    "            fl = sar[\"forecast_ci_lower\"]\n",
    "            fu = sar[\"forecast_ci_upper\"]\n",
    "            eff = sar[\"effect\"]\n",
    "            # pointwise table head\n",
    "            print(\"\\n--- Pointwise effect (first 10 rows) ---\")\n",
    "            print(pd.DataFrame({\n",
    "                \"y_obs\": sar[\"y_post\"],\n",
    "                \"forecast\": fm,\n",
    "                \"ci_lower\": fl,\n",
    "                \"ci_upper\": fu,\n",
    "                \"effect\": eff\n",
    "            }).head(10))\n",
    "            print(f\"\\nCUMULATIVE EFFECT = {sar['cum_effect']:.3f}  95%CI ≈ {sar['cum_ci']}\")\n",
    "\n",
    "            # Plot: observed, forecast, CI, effects\n",
    "            plt.figure(figsize=(12,5))\n",
    "            ax = plt.gca()\n",
    "            # Plot full series\n",
    "            plt.plot(data.index, data.iloc[:,0], label=\"Observed\", color=\"black\", lw=1)\n",
    "            # Forecast area\n",
    "            plt.plot(fm.index, fm.values, label=\"Counterfactual (forecast)\", color=\"C1\", lw=1.5)\n",
    "            plt.fill_between(fm.index, fl.values, fu.values, color=\"C1\", alpha=0.2, label=\"Forecast 95% CI\")\n",
    "            # Mark intervention\n",
    "            if isinstance(data.index, pd.DatetimeIndex):\n",
    "                plt.axvline(post[0], ls=\"--\", color=\"gray\", label=\"Intervention\")\n",
    "            else:\n",
    "                plt.axvline(post[0], ls=\"--\", color=\"gray\", label=\"Intervention\")\n",
    "            plt.title(\"Observed vs Counterfactual Forecast\")\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "            # Plot effects\n",
    "            plt.figure(figsize=(10,4))\n",
    "            plt.plot(eff.index, eff.values, marker=\"o\", label=\"Pointwise effect\")\n",
    "            plt.fill_between(eff.index, sar[\"effect_lower\"].values, sar[\"effect_upper\"].values, color=\"C2\", alpha=0.2, label=\"Effect 95% CI\")\n",
    "            plt.axhline(0, color=\"gray\", lw=0.7)\n",
    "            plt.title(\"Post-intervention Pointwise Effects\")\n",
    "            plt.legend(); plt.tight_layout(); plt.show()\n",
    "            print(\"Method used: SARIMAX (fallback)\")\n",
    "        except Exception as e:\n",
    "            print(\"[error] SARIMAX fallback failed:\", e)\n",
    "            print(\"[info] Falling back to DID/OLS with HAC standard errors.\")\n",
    "            try:\n",
    "                res = run_did_ols(data, pre, post)\n",
    "                print(\"Method used: DID-OLS\")\n",
    "            except Exception as e2:\n",
    "                print(\"[error] DID-OLS also failed:\", e2)\n",
    "                print(\"No further fallbacks available.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6843c569-a7c5-4a71-b11f-b72c6794d947",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
